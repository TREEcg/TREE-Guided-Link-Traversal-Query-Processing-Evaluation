"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.ingest = void 0;
const types_1 = require("@treecg/types");
const mongodb_1 = require("mongodb");
const n3_1 = require("n3");
const process_1 = require("process");
const winston_1 = __importDefault(require("winston"));
const fragmentHelper_1 = require("./fragmentHelper");
const consoleTransport = new winston_1.default.transports.Console();
const logger = winston_1.default.createLogger({
    format: winston_1.default.format.combine(winston_1.default.format.colorize({ level: true }), winston_1.default.format.simple()), transports: [consoleTransport]
});
consoleTransport.level = process.env.LOG_LEVEL || "debug";
// Set<String> yikes!
function filterMember(quads, id, blacklist = [], done) {
    const d = done === undefined ? new Set() : done;
    const quadIsBlacklisted = (q) => blacklist.some(b => b(q, id));
    d.add(id.value);
    const out = quads.filter(q => q.subject.equals(id) && !quadIsBlacklisted(q));
    const newObjects = quads.filter(q => q.subject.equals(id) && !quadIsBlacklisted(q)).map(q => q.object).filter(o => o.termType === "BlankNode" || o.termType === "NamedNode");
    for (let id of newObjects) {
        if (d.has(id.value))
            continue;
        out.push(...filterMember(quads, id, blacklist, d));
    }
    const newSubjects = quads.filter(q => q.object.equals(id) && !quadIsBlacklisted(q)).map(q => q.subject).filter(o => o.termType === "BlankNode" || o.termType === "NamedNode");
    for (let id of newSubjects) {
        if (d.has(id.value))
            continue;
        out.push(...filterMember(quads, id, blacklist, d));
    }
    return out;
}
function ingest(sr, metacollection, dataCollection, indexCollectionName, timestampFragmentation, mUrl, maxSize = 10) {
    return __awaiter(this, void 0, void 0, function* () {
        const url = mUrl || process_1.env.DB_CONN_STRING || "mongodb://localhost:27017/ldes";
        logger.debug("Using mongo url " + url);
        // Connect to database
        const mongo = yield new mongodb_1.MongoClient(url).connect();
        logger.debug("Connected");
        const db = mongo.db();
        const streamTimestampPaths = {};
        let ingestMetadata = true;
        let ingestData = true;
        let closed = false;
        const closeMongo = () => {
            if (!ingestMetadata && !ingestData && !closed) {
                logger.info("Closing mongo");
                closed = true;
                return mongo.close();
            }
        };
        sr.metadata.on("end", () => {
            ingestMetadata = false;
            return closeMongo();
        });
        sr.data.on("end", () => {
            ingestData = false;
            return closeMongo();
        });
        const metaCollection = db.collection(metacollection);
        const dbFragmentations = yield metaCollection.find({ "type": "fragmentation" })
            .map(entry => { return { id: entry.id, quads: new n3_1.Parser().parse(entry.value) }; })
            .toArray();
        logger.debug(`Found ${dbFragmentations.length} fragmentations (${dbFragmentations.map(x => x.id.value)})`);
        const handleMetadata = (meta) => __awaiter(this, void 0, void 0, function* () {
            var _a, _b;
            if (!ingestMetadata) {
                logger.error("Cannot handle metadata, mongo is closed");
                return;
            }
            const streams = meta.filter(q => q.predicate.equals(types_1.RDF.terms.type) && q.object.equals(types_1.SDS.terms.Stream)).map(q => q.subject);
            for (let streamId of streams) {
                const streamMember = filterMember(meta, streamId, [
                    (q, id) => q.predicate.equals(types_1.PROV.terms.used) && q.object.equals(id),
                    (q, id) => q.predicate.equals(types_1.SDS.terms.dataset) && q.object.equals(id),
                ]);
                const datasetId = (_a = streamMember.find(q => q.subject.equals(streamId) && q.predicate.equals(types_1.SDS.terms.dataset))) === null || _a === void 0 ? void 0 : _a.object;
                if (datasetId) {
                    const timestampPathObject = (_b = streamMember.find(q => q.subject.equals(datasetId) && q.predicate.equals(types_1.LDES.terms.timestampPath))) === null || _b === void 0 ? void 0 : _b.object;
                    if (timestampPathObject) {
                        streamTimestampPaths[streamId.value] = timestampPathObject;
                    }
                }
                const timestampPath = streamTimestampPaths[streamId.value];
                logger.debug(`Update metadata for ${streamId.value} (datasetId ${datasetId === null || datasetId === void 0 ? void 0 : datasetId.value}, timestampPath ${timestampPath === null || timestampPath === void 0 ? void 0 : timestampPath.value})`);
                const ser = new n3_1.Writer().quadsToString(streamMember);
                yield metaCollection.updateOne({ "type": types_1.SDS.Stream, "id": streamId.value }, { $set: { value: ser } }, { upsert: true });
            }
        });
        sr.metadata.data(handleMetadata);
        if (sr.metadata.lastElement) {
            handleMetadata(sr.metadata.lastElement);
        }
        const memberCollection = db.collection(dataCollection);
        const indexCollection = db.collection(indexCollectionName);
        sr.data.data((data) => __awaiter(this, void 0, void 0, function* () {
            var _c, _d, _e;
            if (!ingestData) {
                logger.error("Cannot handle data, mongo is closed");
                return;
            }
            const records = data.filter(q => q.predicate.equals(types_1.SDS.terms.payload));
            const idsDone = new Set();
            const timestampValueCache = {};
            const getTimestampValue = (record) => {
                var _a, _b;
                // only correct use of 'in'
                if (record.value in timestampValueCache) {
                    return timestampValueCache[record.subject.value];
                }
                const streamId = (_a = data.find(q => q.predicate.equals(types_1.SDS.terms.stream) && q.subject.equals(record.subject))) === null || _a === void 0 ? void 0 : _a.object;
                const timestampPath = streamId ? streamTimestampPaths[streamId.value] : undefined;
                const timestampValue = timestampPath ? (_b = data.find(quad => quad.subject.equals(record.object) && quad.predicate.equals(timestampPath))) === null || _b === void 0 ? void 0 : _b.object : undefined;
                timestampValueCache[record.subject.value] = timestampValue;
                return timestampValue;
            };
            for (let record of records) {
                const id = record.object;
                if (idsDone.has(id.value))
                    continue;
                idsDone.add(id.value);
                const present = (yield memberCollection.count({ id: id.value })) > 0;
                if (present)
                    continue;
                const timestampValue = (_c = getTimestampValue(record)) === null || _c === void 0 ? void 0 : _c.value;
                logger.debug("Adding member " + id.value);
                const member = filterMember(data, id, [(q) => q.predicate.equals(types_1.SDS.terms.payload)]);
                const ser = new n3_1.Writer().quadsToString(member);
                yield memberCollection.insertOne({ id: id.value, data: ser, timestamp: timestampValue });
            }
            const handledRelations = new Set();
            for (let r of records) {
                const recordId = r.subject;
                const memberId = r.object;
                const rec = data.filter(q => q.subject.equals(recordId));
                const streamsHandled = yield indexCollection.find({ memberId: memberId }).map(entry => entry.streamId).toArray();
                const stream = (_d = rec.find(rec => rec.predicate.equals(types_1.SDS.terms.stream))) === null || _d === void 0 ? void 0 : _d.object;
                // stream not found, can't do anything
                if (!stream) {
                    const ser = new n3_1.Writer().quadsToString(rec);
                    logger.warn("Found record without streams\n" + ser);
                    continue;
                }
                // stream already handled, gtfo
                if (streamsHandled.some(s => s == stream.value)) {
                    continue;
                }
                const timestampValue = (_e = getTimestampValue(r)) === null || _e === void 0 ? void 0 : _e.value;
                const timestampPath = streamTimestampPaths[stream.value];
                const buckets = rec.filter(rec => rec.predicate.equals(types_1.SDS.terms.bucket)).map(b => b.object);
                if (buckets.length == 0) {
                    console.log("no buckets found, only handling timestamp thing");
                    if (timestampValue) {
                        yield (0, fragmentHelper_1.handleTimestampPath)("", stream.value, timestampPath.value, timestampValue, memberId.value, indexCollection, maxSize);
                    }
                    else {
                        // no bucket and no timestamp value :(
                        logger.debug("No timestamp path or bucket found, what is life?");
                        indexCollection.updateOne({ root: true, leaf: true, streamId: stream.value, id: "" }, { $push: { members: memberId.value } }, { upsert: true });
                    }
                }
                else {
                    // insert bucket information
                    const leaf = !timestampValue;
                    for (let bucket of buckets) {
                        const relations = data.filter(q => q.predicate.equals(types_1.SDS.terms.relation) && (data.some(q2 => q2.subject.equals(q.object) && q2.predicate.equals(types_1.SDS.terms.relationBucket) && q2.object.equals(bucket)) ||
                            q.subject.equals(bucket)));
                        for (let relation of relations) {
                            const sourceBucket = relation.subject;
                            const relId = relation.object;
                            if (handledRelations.has(relId))
                                continue;
                            handledRelations.add(relId);
                            const relObj = data.filter(q => q.subject.equals(relId));
                            const type = relObj.find(q => q.predicate.equals(types_1.SDS.terms.relationType)).object.value;
                            const target = relObj.find(q => q.predicate.equals(types_1.SDS.terms.relationBucket)).object.value;
                            const path = relObj.find(q => q.predicate.equals(types_1.SDS.terms.relationPath)).object.value;
                            const value = relObj.find(q => q.predicate.equals(types_1.SDS.terms.relationValue)).object.value;
                            const newRelation = { type, value, bucket: target, path };
                            yield indexCollection.updateOne({ leaf, streamId: stream.value, id: sourceBucket.value }, { "$push": { relations: newRelation } }, { "upsert": true });
                        }
                    }
                    if (timestampValue) {
                        console.log(timestampPath.value);
                        yield Promise.all(buckets.map(bucket => (0, fragmentHelper_1.handleTimestampPath)(bucket.value, stream.value, timestampPath.value, timestampValue, memberId.value, indexCollection, maxSize)));
                    }
                    else {
                        yield Promise.all(buckets.map(bucket => indexCollection.updateOne({ leaf: true, streamId: stream.value, id: bucket.value }, { $push: { members: memberId.value } }, { upsert: true })));
                    }
                }
            }
        }));
    });
}
exports.ingest = ingest;
